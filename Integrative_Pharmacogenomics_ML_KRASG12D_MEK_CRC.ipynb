{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1f007",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 1‚Äì4: Omics Integration (CCLE + GDSC + Mutations ‚Üí Reference Drug)\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ===========================\n",
    "# Load CCLE expression\n",
    "# ===========================\n",
    "expr_file = \"CCLE_expression.csv\"\n",
    "info_file = \"sample_info.csv\"\n",
    "if not os.path.exists(expr_file) or not os.path.exists(info_file):\n",
    "    raise FileNotFoundError(\"Download CCLE_expression.csv and sample_info.csv from DepMap\")\n",
    "\n",
    "df_expr = pd.read_csv(expr_file)\n",
    "KRAS_cols = [c for c in df_expr.columns if \"KRAS\" in c.upper()]\n",
    "if not KRAS_cols:\n",
    "    raise ValueError(\"KRAS column not found in expression file\")\n",
    "KRAS_col = KRAS_cols[0]\n",
    "id_col = \"Unnamed: 0\"\n",
    "expr = df_expr[[id_col, KRAS_col]].copy()\n",
    "expr.columns = [\"cell_line_id\", \"KRAS_expr\"]\n",
    "\n",
    "# Merge expression with metadata\n",
    "info = pd.read_csv(info_file)\n",
    "merged_expr = expr.merge(info, left_on=\"cell_line_id\", right_on=\"ModelID\", how=\"left\")\n",
    "\n",
    "# Filter only colon/colorectal lines\n",
    "crc_diseases = [\"Colon\", \"Colorectal\"]\n",
    "crc_expr = merged_expr[\n",
    "    merged_expr[\"OncotreePrimaryDisease\"].str.contains('|'.join(crc_diseases), case=False, na=False)\n",
    "].copy()\n",
    "crc_expr_sorted = crc_expr.sort_values(\"KRAS_expr\", ascending=False)\n",
    "crc_expr_sorted.to_csv(\"KRAS_high_crc.csv\", index=False)\n",
    "\n",
    "# ===========================\n",
    "# Harmonize GDSC data\n",
    "# ===========================\n",
    "ic50_file = \"GDSC2_fitted_dose_response.csv\"\n",
    "cell_info_file = \"Cell_Lines_Details.csv\"\n",
    "if not os.path.exists(ic50_file) or not os.path.exists(cell_info_file):\n",
    "    raise FileNotFoundError(\"Download GDSC2_fitted_dose_response.csv and Cell_Lines_Details.csv\")\n",
    "\n",
    "ic50 = pd.read_csv(ic50_file)\n",
    "cell_info = pd.read_csv(cell_info_file)\n",
    "cell_info.rename(columns={'COSMIC identifier': 'COSMIC_ID',\n",
    "                          'Sample Name': 'CellLineName'}, inplace=True)\n",
    "\n",
    "# Clean and align IDs\n",
    "cell_info = cell_info.dropna(subset=['COSMIC_ID']).copy()\n",
    "cell_info['COSMIC_ID'] = cell_info['COSMIC_ID'].astype(float).astype(int)\n",
    "crc_expr_sorted = crc_expr_sorted.dropna(subset=['COSMICID']).copy()\n",
    "crc_expr_sorted['COSMICID'] = crc_expr_sorted['COSMICID'].astype(float).astype(int)\n",
    "ic50 = ic50.dropna(subset=['COSMIC_ID']).copy()\n",
    "ic50['COSMIC_ID'] = ic50['COSMIC_ID'].astype(int)\n",
    "\n",
    "# Merge CRC expression ‚Üí GDSC info\n",
    "merged_crc = crc_expr_sorted.merge(\n",
    "    cell_info[['COSMIC_ID', 'CellLineName']],\n",
    "    left_on='COSMICID', right_on='COSMIC_ID', how='inner'\n",
    ")\n",
    "print(\"CRC lines mapped:\", merged_crc['cell_line_id'].nunique())\n",
    "\n",
    "# Subset IC50 for mapped CRC lines\n",
    "ic50_crc = ic50[ic50['COSMIC_ID'].isin(merged_crc['COSMIC_ID'])].copy()\n",
    "ic50_crc.to_csv(\"CRC_ic50_intersection.csv\", index=False)\n",
    "\n",
    "# ===========================\n",
    "# Merge expression + IC50 for selected drugs\n",
    "# ===========================\n",
    "expr_small = merged_crc[['cell_line_id', 'KRAS_expr', 'COSMICID']].copy()\n",
    "selected_drugs = [\"Afatinib\", \"Gefitinib\", \"Refametinib\", \"Navitoclax\", \"PLX-4720\",\n",
    "                  \"Trametinib\", \"Selumetinib\", \"Sotorasib\", \"Adagrasib\"]\n",
    "\n",
    "ic50_selected = ic50_crc[ic50_crc['DRUG_NAME'].isin(selected_drugs)].copy()\n",
    "merged_multi = pd.merge(\n",
    "    expr_small,\n",
    "    ic50_selected[['COSMIC_ID', 'DRUG_NAME', 'LN_IC50']],\n",
    "    left_on='COSMICID', right_on='COSMIC_ID', how='inner'\n",
    ")\n",
    "merged_multi.to_csv(\"KRAS_expr_multi_drugs.csv\", index=False)\n",
    "\n",
    "# ===========================\n",
    "# Add KRAS mutation data\n",
    "# ===========================\n",
    "mut_file = \"CCLE_mutations.csv\"\n",
    "if not os.path.exists(mut_file):\n",
    "    raise FileNotFoundError(\"Download CCLE_mutations.csv from DepMap\")\n",
    "\n",
    "df_mut = pd.read_csv(mut_file)\n",
    "kras_mut = df_mut[df_mut['Hugo_Symbol'].str.upper() == \"KRAS\"]\n",
    "cols = ['DepMap_ID', 'Hugo_Symbol', 'Protein_Change', 'Variant_Classification',\n",
    "        'Chromosome', 'Start_position', 'End_position', 'Variant_Type']\n",
    "kras_mut = kras_mut[cols]\n",
    "\n",
    "merged_with_mut = merged_multi.merge(kras_mut, left_on=\"cell_line_id\", right_on=\"DepMap_ID\", how=\"left\")\n",
    "merged_with_mut.to_csv(\"KRAS_expr_ic50_mut.csv\", index=False)\n",
    "\n",
    "# ===========================\n",
    "# Correlation analysis\n",
    "# ===========================\n",
    "df_corr = merged_with_mut.dropna(subset=[\"KRAS_expr\", \"LN_IC50\"])\n",
    "results = []\n",
    "for drug in df_corr['DRUG_NAME'].unique():\n",
    "    sub = df_corr[df_corr['DRUG_NAME'] == drug]\n",
    "    if len(sub) > 5:\n",
    "        r, p = pearsonr(sub['KRAS_expr'].astype(float), sub['LN_IC50'].astype(float))\n",
    "        results.append({\"drug\": drug, \"pearson_r\": r, \"p_value\": p, \"n\": len(sub)})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"pearson_r\")\n",
    "results_df.to_csv(\"drug_correlation_results.csv\", index=False)\n",
    "print(\"Correlation results saved: drug_correlation_results.csv\")\n",
    "print(results_df.head())\n",
    "\n",
    "# ===========================\n",
    "# Reference drug selection\n",
    "# ===========================\n",
    "reference_drug = results_df.iloc[0]['drug']\n",
    "kras_pathway_drugs = [\"Sotorasib\", \"Adagrasib\", \"Trametinib\", \"Selumetinib\"]\n",
    "if reference_drug not in kras_pathway_drugs:\n",
    "    available = [d for d in kras_pathway_drugs if d in df_corr['DRUG_NAME'].unique()]\n",
    "    if available:\n",
    "        print(f\"Overriding to biologically relevant drug: {available[0]}\")\n",
    "        reference_drug = available[0]\n",
    "print(\"Final chosen reference drug:\", reference_drug)\n",
    "\n",
    "# ===========================\n",
    "# Visualization\n",
    "# ===========================\n",
    "for drug in df_corr['DRUG_NAME'].unique():\n",
    "    sub = df_corr[df_corr['DRUG_NAME'] == drug]\n",
    "    if len(sub) > 5:\n",
    "        x = sub['KRAS_expr'].astype(float)\n",
    "        y = sub['LN_IC50'].astype(float)\n",
    "        r, p = pearsonr(x, y)\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.scatter(x, y, alpha=0.7)\n",
    "        plt.xlabel(\"KRAS expression (log2 TPM+1)\")\n",
    "        plt.ylabel(\"LN_IC50\")\n",
    "        plt.title(f\"{drug}: r={r:.2f}, p={p:.2e}\")\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{drug}_expr_vs_ic50.png\", dpi=200)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be62f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#step 5 the scrna wala step\n",
    "# =========================\n",
    "# Install dependencies (only first time)\n",
    "# =========================\n",
    "# !pip install scanpy==1.9.3 anndata==0.8.0 matplotlib seaborn pandas scipy\n",
    "\n",
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "from scipy.io import mmread\n",
    "\n",
    "# =========================\n",
    "# File paths (adjust if needed)\n",
    "# =========================\n",
    "matrix_file = \"matrix.mtx\"\n",
    "genes_file = \"genes.csv\"      # or features.tsv\n",
    "barcodes_file = \"barcodes.csv\"\n",
    "clinical_file = \"table.csv\"   # <-- using CSV now\n",
    "\n",
    "# =========================\n",
    "# Load metadata\n",
    "# =========================\n",
    "genes = pd.read_csv(genes_file, header=None, sep=None, engine=\"python\")\n",
    "genes.columns = [\"gene_id\", \"gene_symbol\"]\n",
    "\n",
    "barcodes = pd.read_csv(barcodes_file, header=None)\n",
    "barcodes.columns = [\"cell_id\"]\n",
    "\n",
    "# =========================\n",
    "# Load matrix (MTX)\n",
    "# =========================\n",
    "X = mmread(matrix_file).tocsr()\n",
    "print(\"Matrix shape (cells x genes):\", X.shape)\n",
    "\n",
    "# =========================\n",
    "# Auto-fix mismatches\n",
    "# =========================\n",
    "# Genes\n",
    "if X.shape[1] != genes.shape[0]:\n",
    "    print(f\"‚ö†Ô∏è Gene mismatch: matrix has {X.shape[1]} genes, file has {genes.shape[0]}\")\n",
    "    min_len = min(X.shape[1], genes.shape[0])\n",
    "    X = X[:, :min_len]\n",
    "    genes = genes.iloc[:min_len, :]\n",
    "    print(\"‚úÖ Fixed genes ->\", min_len)\n",
    "\n",
    "# Barcodes\n",
    "if X.shape[0] != barcodes.shape[0]:\n",
    "    print(f\"‚ö†Ô∏è Barcode mismatch: matrix has {X.shape[0]} cells, file has {barcodes.shape[0]}\")\n",
    "    min_len = min(X.shape[0], barcodes.shape[0])\n",
    "    X = X[:min_len, :]\n",
    "    barcodes = barcodes.iloc[:min_len, :]\n",
    "    print(\"‚úÖ Fixed barcodes ->\", min_len)\n",
    "\n",
    "# =========================\n",
    "# Create AnnData\n",
    "# =========================\n",
    "adata = sc.AnnData(X)\n",
    "adata.var['gene_symbol'] = genes['gene_symbol'].values\n",
    "adata.obs['cell_id'] = barcodes['cell_id'].values\n",
    "\n",
    "adata.obs.set_index('cell_id', inplace=True)\n",
    "adata.var.set_index('gene_symbol', inplace=True)\n",
    "\n",
    "# =========================\n",
    "# Merge clinical metadata (optional)\n",
    "# =========================\n",
    "if os.path.exists(clinical_file):\n",
    "    clinical = pd.read_csv(clinical_file)\n",
    "    adata.obs['Patient_ID'] = [c.split(\"_\")[1] for c in adata.obs_names]\n",
    "    adata.obs = adata.obs.merge(clinical, how='left',\n",
    "                                left_on='Patient_ID', right_on='Patient ID')\n",
    "    print(\"‚úÖ Clinical metadata merged.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Clinical file not found, skipping merge.\")\n",
    "\n",
    "# =========================\n",
    "# Basic QC\n",
    "# =========================\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], inplace=True)\n",
    "\n",
    "# =========================\n",
    "# Normalization & HVG\n",
    "# =========================\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "\n",
    "# =========================\n",
    "# PCA, neighbors, UMAP, clustering\n",
    "# =========================\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata)\n",
    "\n",
    "# =========================\n",
    "# Save plots (optimized for speed)\n",
    "# =========================\n",
    "sc.pl.umap(adata, color=['leiden'], size=5, dpi=80, show=False, save='_clusters.png')\n",
    "\n",
    "if 'KRAS' in adata.var_names:\n",
    "    sc.pl.umap(adata, color=['KRAS'], size=5, dpi=80, show=False, save='_kras.png')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è KRAS gene not found. Check var_names:\", adata.var_names[:10])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Save processed AnnData\n",
    "# =========================\n",
    "adata.write(\"GSE178318_processed.h5ad\")\n",
    "print(\"‚úÖ Saved processed AnnData: GSE178318_processed.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29540c2b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# üìò Step 6: ChEMBL Data Processing Pipeline\n",
    "# From raw target CSVs ‚Üí cleaned, standardized dataset\n",
    "# Author: [Your Name]\n",
    "# ================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, MACCSkeys\n",
    "\n",
    "# ================================================\n",
    "# Step 1: Define Input Files (ChEMBL Downloads)\n",
    "# ================================================\n",
    "files = {\n",
    "    \"SOS1-KRAS\": r\"C:\\Users\\HomePC\\Desktop\\lab\\MTDLs\\asinex\\chem\\CHEMBL5465393 (SOS1-KRAS).csv\",\n",
    "    \"KRAS\": r\"C:\\Users\\HomePC\\Desktop\\lab\\MTDLs\\asinex\\chem\\CHEMBL2189121 (GTPase KRas).csv\",\n",
    "    \"MEK\": r\"C:\\Users\\HomePC\\Desktop\\lab\\MTDLs\\asinex\\chem\\CHEMBL2111351.csv\"\n",
    "}\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "# ================================================\n",
    "# Step 2: Clean and Standardize Each File\n",
    "# ================================================\n",
    "for target, file in files.items():\n",
    "    df = pd.read_csv(file, sep=\";\")\n",
    "\n",
    "    # Keep key columns (adjust if names differ)\n",
    "    keep = [\n",
    "        \"Molecule ChEMBL ID\", \"Smiles\", \"Molecular Weight\",\n",
    "        \"AlogP\", \"#RO5 Violations\", \"Standard Type\",\n",
    "        \"Value\", \"Standard Units\"\n",
    "    ]\n",
    "    df = df[[c for c in keep if c in df.columns]].copy()\n",
    "    df = df[df[\"Value\"].notna()]\n",
    "    df[\"Value\"] = pd.to_numeric(df[\"Value\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Value\"])\n",
    "\n",
    "    # Convert all IC50/Activity values to nM\n",
    "    def to_nM(row):\n",
    "        unit = str(row[\"Standard Units\"]).lower()\n",
    "        val = row[\"Value\"]\n",
    "        if unit == \"nm\":\n",
    "            return val\n",
    "        elif unit == \"¬µm\" or unit == \"um\":\n",
    "            return val * 1_000\n",
    "        elif unit == \"mm\":\n",
    "            return val * 1_000_000\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    df[\"IC50_nM\"] = df.apply(to_nM, axis=1)\n",
    "    df = df.dropna(subset=[\"IC50_nM\"])\n",
    "\n",
    "    # Label by activity thresholds\n",
    "    df[\"Activity_Class\"] = \"Intermediate\"\n",
    "    df.loc[df[\"IC50_nM\"] <= 1000, \"Activity_Class\"] = \"Active\"\n",
    "    df.loc[df[\"IC50_nM\"] >= 10000, \"Activity_Class\"] = \"Inactive\"\n",
    "\n",
    "    # Add Target info\n",
    "    df[\"Target\"] = target\n",
    "\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# ================================================\n",
    "# Step 3: Merge All Targets\n",
    "# ================================================\n",
    "combined = pd.concat(all_dfs, ignore_index=True)\n",
    "combined.to_csv(\"chembl_combined_clean.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Saved ‚Üí chembl_combined_clean.csv\")\n",
    "print(\"Shape:\", combined.shape)\n",
    "print(\"Counts per target:\\n\", combined[\"Target\"].value_counts())\n",
    "print(\"Activity class distribution:\\n\", combined[\"Activity_Class\"].value_counts())\n",
    "\n",
    "# ================================================\n",
    "# Step 4: Convert IC50 ‚Üí pIC50 and Apply Lipinski Rules\n",
    "# ================================================\n",
    "df = combined.copy()\n",
    "df[\"pIC50\"] = 9 - np.log10(df[\"IC50_nM\"])\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"pIC50\"])\n",
    "\n",
    "# Compute Lipinski descriptors\n",
    "def lipinski(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return pd.Series([np.nan] * 5)\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    hbd = Descriptors.NumHDonors(mol)\n",
    "    hba = Descriptors.NumHAcceptors(mol)\n",
    "    ro5 = sum([mw > 500, logp > 5, hbd > 5, hba > 10])\n",
    "    return pd.Series([mw, logp, hbd, hba, ro5])\n",
    "\n",
    "df[[\"MW\", \"LogP\", \"HBD\", \"HBA\", \"RO5\"]] = df[\"Smiles\"].apply(lipinski)\n",
    "\n",
    "# ================================================\n",
    "# Step 5: Reassign Activity Classes by pIC50\n",
    "# ================================================\n",
    "def label_activity(pIC50):\n",
    "    if pIC50 >= 6:\n",
    "        return \"Active\"\n",
    "    elif pIC50 <= 5:\n",
    "        return \"Inactive\"\n",
    "    else:\n",
    "        return \"Intermediate\"\n",
    "\n",
    "df[\"Activity_Class\"] = df[\"pIC50\"].apply(label_activity)\n",
    "\n",
    "# ================================================\n",
    "# Step 6: Generate Molecular Fingerprints\n",
    "# ================================================\n",
    "def morgan_fp(smiles, radius=2, nBits=2048):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits) if mol else None\n",
    "\n",
    "def maccs_fp(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return MACCSkeys.GenMACCSKeys(mol) if mol else None\n",
    "\n",
    "df[\"MorganFP\"] = df[\"Smiles\"].apply(morgan_fp)\n",
    "df[\"MACCSFP\"] = df[\"Smiles\"].apply(maccs_fp)\n",
    "\n",
    "# ================================================\n",
    "# Step 7: Save Final Processed Dataset\n",
    "# ================================================\n",
    "df.to_csv(\"chembl_processed.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Final dataset saved ‚Üí chembl_processed.csv\")\n",
    "print(\"Final shape:\", df.shape)\n",
    "print(\"Activity class balance:\\n\", df[\"Activity_Class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76def4a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ML + Selumetinib similarity integration\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MACCSkeys\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ================================\n",
    "# Step 1: Load datasets\n",
    "# ================================\n",
    "df = pd.read_csv(\"chembl_processed.csv\")\n",
    "similarity = pd.read_csv(\"selumetinib_similarity_filtered.csv\")\n",
    "\n",
    "# Keep only Active vs Inactive (drop intermediates)\n",
    "df = df[df[\"Activity_Class\"].isin([\"Active\", \"Inactive\"])].copy()\n",
    "df[\"y\"] = df[\"Activity_Class\"].map({\"Active\": 1, \"Inactive\": 0})\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# ================================\n",
    "# Step 2: Fingerprint generation\n",
    "# ================================\n",
    "def mol_to_fps(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None, None\n",
    "    morgan = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    maccs = MACCSkeys.GenMACCSKeys(mol)\n",
    "    return np.array(morgan), np.array(maccs)\n",
    "\n",
    "fps_morgan, fps_maccs = [], []\n",
    "for smi in df[\"Smiles\"]:\n",
    "    m, a = mol_to_fps(smi)\n",
    "    if m is None:\n",
    "        fps_morgan.append([0]*2048)\n",
    "        fps_maccs.append([0]*167)\n",
    "    else:\n",
    "        fps_morgan.append(m)\n",
    "        fps_maccs.append(a)\n",
    "\n",
    "X_morgan = np.array(fps_morgan)\n",
    "X_maccs = np.array(fps_maccs)\n",
    "y = df[\"y\"].values\n",
    "\n",
    "# ================================\n",
    "# Step 3: Define models\n",
    "# ================================\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", C=1, gamma=0.1, probability=True, random_state=42),\n",
    "    \"ANN\": MLPClassifier(hidden_layer_sizes=(128, 64), activation=\"relu\",\n",
    "                         solver=\"adam\", max_iter=200, random_state=42)\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# Step 4: Cross-validation & evaluation\n",
    "# ================================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "performance = []\n",
    "\n",
    "preds_all = pd.DataFrame({\"Molecule ChEMBL ID\": df[\"Molecule ChEMBL ID\"], \"True_Label\": y})\n",
    "\n",
    "for name, model in models.items():\n",
    "    preds = cross_val_predict(model, X_morgan, y, cv=skf, method=\"predict_proba\")[:, 1]\n",
    "    y_pred = (preds >= 0.5).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(y, preds)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    prec = precision_score(y, y_pred)\n",
    "    rec = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "\n",
    "    performance.append([name, auc, acc, prec, rec, f1])\n",
    "\n",
    "    preds_all[f\"{name}_prob\"] = preds\n",
    "\n",
    "perf_df = pd.DataFrame(performance, columns=[\"Model\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "perf_df.to_csv(\"ml_performance.csv\", index=False)\n",
    "preds_all.to_csv(\"ml_predictions.csv\", index=False)\n",
    "\n",
    "print(\"\\nML Performance:\")\n",
    "print(perf_df)\n",
    "\n",
    "# ================================\n",
    "# Step 5: Merge with Selumetinib similarity\n",
    "# ================================\n",
    "merged = preds_all.merge(similarity, on=\"Molecule ChEMBL ID\", how=\"inner\")\n",
    "\n",
    "# Use RF as main model for ranking\n",
    "merged[\"Rank_Score\"] = merged[\"RandomForest_prob\"] * (\n",
    "    merged[\"Morgan_Similarity\"] + merged[\"MACCS_Similarity\"]\n",
    ") / 2\n",
    "\n",
    "# Sort best to worst\n",
    "top_hits = merged.sort_values(\"Rank_Score\", ascending=False)\n",
    "top_hits.to_csv(\"top_hits_pre_docking.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Final shortlist saved ‚Üí top_hits_pre_docking.csv\")\n",
    "print(top_hits.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f065a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Step 1: Load top hits to filter by criteria\n",
    "# =========================================\n",
    "import pandas as pd\n",
    "\n",
    "hits = pd.read_csv(\"top_hits_pre_docking.csv\")\n",
    "\n",
    "# =========================================\n",
    "# Step 2: Apply strict consensus filters\n",
    "# =========================================\n",
    "filtered = hits[\n",
    "    (hits[\"Rank_Score\"] >= 0.35) &\n",
    "    (hits[\"RandomForest_prob\"] >= 0.95) &\n",
    "    (hits[\"SVM_prob\"] >= 0.85) &\n",
    "    (hits[\"ANN_prob\"] >= 0.99) &\n",
    "    (hits[\"Activity_Class\"] == \"Active\")   # keep only experimental actives\n",
    "].copy()\n",
    "\n",
    "print(\"Filtered consensus hits:\", filtered.shape[0])\n",
    "\n",
    "# =========================================\n",
    "# Step 3: Save for docking\n",
    "# =========================================\n",
    "filtered.to_csv(\"consensus_hits_for_docking.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Saved ‚Üí consensus_hits_for_docking.csv\")\n",
    "print(filtered.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
